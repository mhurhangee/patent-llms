{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle cell: resume training + push checkpoints to HF\n!pip -q install -U transformers datasets accelerate huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:50:51.952272Z","iopub.execute_input":"2025-08-12T15:50:51.952478Z","iopub.status.idle":"2025-08-12T15:52:28.271226Z","shell.execute_reply.started":"2025-08-12T15:50:51.952461Z","shell.execute_reply":"2025-08-12T15:52:28.270460Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os, math\nfrom pathlib import Path\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login, snapshot_download\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaForMaskedLM, RobertaTokenizerFast,\n    DataCollatorForLanguageModeling, Trainer, TrainingArguments\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:58:53.613281Z","iopub.execute_input":"2025-08-12T15:58:53.613664Z","iopub.status.idle":"2025-08-12T15:58:53.618727Z","shell.execute_reply.started":"2025-08-12T15:58:53.613636Z","shell.execute_reply":"2025-08-12T15:58:53.617875Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"repo128 = \"mhurhangee/patroberta-mlm-sl128-v8000\"\nrepo256 = \"mhurhangee/patroberta-mlm-sl256-v8000\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:58:55.709827Z","iopub.execute_input":"2025-08-12T15:58:55.710073Z","iopub.status.idle":"2025-08-12T15:58:55.713698Z","shell.execute_reply.started":"2025-08-12T15:58:55.710056Z","shell.execute_reply":"2025-08-12T15:58:55.713021Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = RobertaForMaskedLM.from_pretrained(repo128) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:59:28.863329Z","iopub.execute_input":"2025-08-12T15:59:28.863661Z","iopub.status.idle":"2025-08-12T15:59:30.452681Z","shell.execute_reply.started":"2025-08-12T15:59:28.863635Z","shell.execute_reply":"2025-08-12T15:59:30.452054Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d243cfe21b934550bb2cc33e69fce4de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03aba8c047414f57a8f080c2e015836e"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"model.gradient_checkpointing_disable()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:59:34.876992Z","iopub.execute_input":"2025-08-12T15:59:34.877761Z","iopub.status.idle":"2025-08-12T15:59:34.881732Z","shell.execute_reply.started":"2025-08-12T15:59:34.877736Z","shell.execute_reply":"2025-08-12T15:59:34.880895Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tok = RobertaTokenizerFast.from_pretrained(repo128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:59:38.666842Z","iopub.execute_input":"2025-08-12T15:59:38.667169Z","iopub.status.idle":"2025-08-12T15:59:39.973281Z","shell.execute_reply.started":"2025-08-12T15:59:38.667145Z","shell.execute_reply":"2025-08-12T15:59:39.972381Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a3730371144cdda8fc26d45ac3661d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b16623735bbd43e0b823be41b2637ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a99b9ab35f455087cafcfa40dd14da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d82a7aa23f4490bbdc73a5e83696272"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e813d0f4a7a416e9febb51dd6acfbe8"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"ds = load_dataset(\"mhurhangee/ep-patent-all-claims\")\ntrain_ds, val_ds = ds[\"train\"], ds[\"validation\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:59:47.009510Z","iopub.execute_input":"2025-08-12T15:59:47.010248Z","iopub.status.idle":"2025-08-12T16:00:09.121329Z","shell.execute_reply.started":"2025-08-12T15:59:47.010212Z","shell.execute_reply":"2025-08-12T16:00:09.120542Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff5ad0bd59748b282592604f21a7fbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bb05ce1ea54451b478582d09dfa6c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9902f29860c947cbb45d00ef15bbe6b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3da9bcf4a26f4b4c87134dabeb62b5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00003-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5acbfd063f234d03b1c35f6f2fa9cdab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00004-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7f070af8f5e49f18ed6062fdaf65483"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00005-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65211ee88a0447abee9e99e6c26aad8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001.parquet:   0%|          | 0.00/18.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97717d37a2ee4ba793b677ea327acebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/18.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f8fd7e7e4e943659d3b9eb858023388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4243904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba785ca92584bff96271180b3b612c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/88415 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61777868e530475fb675ca86ae7dee4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/88415 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084ca27b2e7448f794f4ada0c897aca8"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"seq_len = 256\ndef enc(b): return tok(b[\"text\"], truncation=True, max_length=seq_len)\ntrain_ds = train_ds.map(enc, batched=True, remove_columns=train_ds.column_names)\nval_ds   = val_ds.map(enc,   batched=True, remove_columns=val_ds.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:01:01.309105Z","iopub.execute_input":"2025-08-12T16:01:01.309828Z","iopub.status.idle":"2025-08-12T16:17:04.359213Z","shell.execute_reply.started":"2025-08-12T16:01:01.309805Z","shell.execute_reply":"2025-08-12T16:17:04.358327Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4243904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"565927e2bf4d42d9904ec46b5a586668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/88415 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476844ed21ed4cfd85070ed482bcb60b"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm=True, mlm_probability=0.15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:23:31.033986Z","iopub.execute_input":"2025-08-12T16:23:31.034654Z","iopub.status.idle":"2025-08-12T16:23:31.038650Z","shell.execute_reply.started":"2025-08-12T16:23:31.034632Z","shell.execute_reply":"2025-08-12T16:23:31.037936Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nhf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = hf_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:25:01.849516Z","iopub.execute_input":"2025-08-12T16:25:01.849749Z","iopub.status.idle":"2025-08-12T16:25:01.959691Z","shell.execute_reply.started":"2025-08-12T16:25:01.849734Z","shell.execute_reply":"2025-08-12T16:25:01.959050Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"./checkpoints\",\n    per_device_train_batch_size=128,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=1,\n    learning_rate=4e-4,\n    weight_decay=0.01,\n    warmup_ratio=0.06,\n    num_train_epochs=4,\n    eval_strategy=\"steps\",\n    eval_steps=1000,\n    save_strategy=\"steps\",\n    save_steps=1000,\n    save_total_limit=4,\n    logging_steps=100,\n    fp16=True,\n    fp16_full_eval=True,\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    remove_unused_columns=False,\n    # Hub pushing\n    push_to_hub=True,\n    hub_model_id=repo256,\n    hub_token=hf_token,\n    hub_private_repo=False,\n    hub_strategy=\"every_save\",   # push each checkpoint on save\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:25:09.715894Z","iopub.execute_input":"2025-08-12T16:25:09.716237Z","iopub.status.idle":"2025-08-12T16:25:09.752718Z","shell.execute_reply.started":"2025-08-12T16:25:09.716207Z","shell.execute_reply":"2025-08-12T16:25:09.751891Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    processing_class=tok,\n    data_collator=collator,\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:25:12.212208Z","iopub.execute_input":"2025-08-12T16:25:12.212558Z","iopub.status.idle":"2025-08-12T16:25:12.625909Z","shell.execute_reply.started":"2025-08-12T16:25:12.212533Z","shell.execute_reply":"2025-08-12T16:25:12.625055Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:25:17.449683Z","iopub.execute_input":"2025-08-12T16:25:17.449967Z","execution_failed":"2025-08-12T20:33:25.746Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='35208' max='66312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [35208/66312 4:08:03 < 3:39:09, 2.37 it/s, Epoch 2.12/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>2.773400</td>\n      <td>2.535119</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.271400</td>\n      <td>1.890647</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.148100</td>\n      <td>1.867113</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.155600</td>\n      <td>1.877035</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.154700</td>\n      <td>1.869903</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.145800</td>\n      <td>1.868883</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.149900</td>\n      <td>1.868450</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.140100</td>\n      <td>1.862905</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.147100</td>\n      <td>1.858026</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.131400</td>\n      <td>1.857904</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.138700</td>\n      <td>1.851923</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.129900</td>\n      <td>1.850705</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.123700</td>\n      <td>1.848130</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.114800</td>\n      <td>1.841224</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.120300</td>\n      <td>1.842028</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.120200</td>\n      <td>1.839450</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.116400</td>\n      <td>1.836440</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.110500</td>\n      <td>1.834632</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.117700</td>\n      <td>1.831053</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.101600</td>\n      <td>1.832942</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>2.106600</td>\n      <td>1.828687</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>2.105800</td>\n      <td>1.824641</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>2.104800</td>\n      <td>1.826995</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>2.103400</td>\n      <td>1.819978</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>2.112600</td>\n      <td>1.819082</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>2.101700</td>\n      <td>1.821526</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>2.084800</td>\n      <td>1.818597</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>2.097300</td>\n      <td>1.814761</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>2.087400</td>\n      <td>1.814756</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>2.094100</td>\n      <td>1.812335</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>2.089200</td>\n      <td>1.809353</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>2.093700</td>\n      <td>1.809391</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>2.089400</td>\n      <td>1.804339</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>2.079900</td>\n      <td>1.807592</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>2.078100</td>\n      <td>1.801077</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"trainer.save_model()\ntokenizer.save_pretrained(args.output_dir)\ntrainer.push_to_hub()    ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}