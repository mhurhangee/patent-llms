{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a146840b",
   "metadata": {},
   "source": [
    "# Extracting Claims from EPO Patent XML Files\n",
    "\n",
    "This notebook processes XML files downloaded from the EPO publication server and extracts:\n",
    "1. Patent number (combining country+number+kind)\n",
    "2. Claims in English language\n",
    "3. Saves output as JSONL files grouped by publication date (YYYYMMDD)\n",
    "\n",
    "The output format is:\n",
    "```json\n",
    "{\n",
    "  \"pn\": \"EP1234567B1\",\n",
    "  \"c\": {\n",
    "    \"1\": \"text of claim 1\",\n",
    "    \"2\": \"text of claim 2\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "*Notebook process*\n",
    "1. Find all XML files in date directories under `INPUT_DIR`\n",
    "2. Extract patent numbers and claims\n",
    "3. Save results as JSONL files in `OUTPUT_DIR` directory named by date (`YYYYMMDD.jsonl`)\n",
    "4. Skip dates that already have a JSONL file for that date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from lxml import etree # pyright: ignore[reportAttributeAccessIssue]\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Input/Output directories\n",
    "INPUT_DIR = \"../rawdata/ep-b1\"\n",
    "OUTPUT_DIR = \"../processed\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6481c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patent_info(xml_file):\n",
    "    \"\"\"Process a single XML file and extract patent number and claims\"\"\"\n",
    "    try:\n",
    "        # Parse XML with recovery mode for potential malformed XML\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = etree.parse(xml_file, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Extract patent number\n",
    "        country = root.get('country', '')\n",
    "        number = root.get('doc-number', '')\n",
    "        kind = root.get('kind', '')\n",
    "        patent_number = f\"{country}{number}{kind}\"\n",
    "\n",
    "        # Extract claims (only English)\n",
    "        claims_dict = {}\n",
    "        claims = root.xpath('//claims[@lang=\"en\"]')\n",
    "        if claims:\n",
    "            for claim in claims[0].xpath('.//claim'):\n",
    "                num = claim.get('num', '').lstrip('0')  # Remove leading zeros\n",
    "                if num:\n",
    "                    # Get all text from claim, handling nested tags\n",
    "                    texts = []\n",
    "                    for text in claim.xpath('.//claim-text'):\n",
    "                        # Process text content and any tail text\n",
    "                        parts = []\n",
    "                        for elem in text.xpath('.//text()'):\n",
    "                            parts.append(elem.strip())\n",
    "                        texts.append(' '.join(filter(None, parts)))\n",
    "                    \n",
    "                    claim_text = '\\n'.join(filter(None, texts))\n",
    "                    claims_dict[f\"{num}\"] = claim_text.strip()\n",
    "\n",
    "        if patent_number and claims_dict:\n",
    "            return {\n",
    "                \"pn\": patent_number,\n",
    "                \"c\": claims_dict\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {xml_file}: {str(e)}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9c389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patent_files():\n",
    "    \"\"\"Process all XML files and save as JSONL grouped by date\"\"\"\n",
    "    # Get all date directories\n",
    "    date_dirs = sorted(glob.glob(os.path.join(INPUT_DIR, '*')))\n",
    "    \n",
    "    for date_dir in date_dirs:\n",
    "        date = os.path.basename(date_dir)\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{date}.jsonl\")\n",
    "        \n",
    "        # Skip if output file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {date} - output file already exists\")\n",
    "            continue\n",
    "        \n",
    "        # Get all XML files in this date directory\n",
    "        xml_files = glob.glob(os.path.join(date_dir, '*.xml'))\n",
    "        if not xml_files:\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing {len(xml_files)} files from {date}\")\n",
    "        \n",
    "        # Process each XML file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                    with ProcessPoolExecutor() as executor:\n",
    "                        futures = {executor.submit(extract_patent_info, xml_file): xml_file for xml_file in xml_files}\n",
    "                        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing {date}\"):\n",
    "                            result = future.result()\n",
    "                            if result:\n",
    "                                f.write(json.dumps(result, ensure_ascii=False) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
