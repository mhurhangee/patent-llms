{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d59d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"val\": {\n",
      "    \"accuracy\": 0.7927686332531904,\n",
      "    \"macro_f1\": 0.7466847279673036,\n",
      "    \"weighted_f1\": 0.79089364393868\n",
      "  },\n",
      "  \"test\": {\n",
      "    \"accuracy\": 0.7968374329572776,\n",
      "    \"macro_f1\": 0.7604504286491491,\n",
      "    \"weighted_f1\": 0.7958749623320344\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Baseline: TF-IDF + Logistic Regression\n",
    "# ================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import json\n",
    "\n",
    "# ---- config ----\n",
    "CSV_DIR = Path(\"../data/cpc_cls\")\n",
    "OUT_METRICS = Path(\"../artifacts/baseline_tfidf_logreg.json\")\n",
    "MAX_FEATURES = 50000  # adjust if memory is low\n",
    "\n",
    "# ---- load data ----\n",
    "train_df = pd.read_csv(CSV_DIR / \"cpc_cls_train.csv\")\n",
    "val_df   = pd.read_csv(CSV_DIR / \"cpc_cls_val.csv\")\n",
    "test_df  = pd.read_csv(CSV_DIR / \"cpc_cls_test.csv\")\n",
    "\n",
    "# ---- vectorize ----\n",
    "tfidf = TfidfVectorizer(max_features=MAX_FEATURES, ngram_range=(1,2))\n",
    "X_train = tfidf.fit_transform(train_df[\"text\"])\n",
    "X_val   = tfidf.transform(val_df[\"text\"])\n",
    "X_test  = tfidf.transform(test_df[\"text\"])\n",
    "\n",
    "# ---- train model ----\n",
    "clf = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "clf.fit(X_train, train_df[\"label\"])\n",
    "\n",
    "# ---- evaluate ----\n",
    "def eval_split(X, y_true):\n",
    "    preds = clf.predict(X)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, preds),\n",
    "        \"macro_f1\": f1_score(y_true, preds, average=\"macro\"),\n",
    "        \"weighted_f1\": f1_score(y_true, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "metrics = {\n",
    "    \"val\": eval_split(X_val, val_df[\"label\"]),\n",
    "    \"test\": eval_split(X_test, test_df[\"label\"]),\n",
    "}\n",
    "\n",
    "# ---- save ----\n",
    "OUT_METRICS.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_METRICS.write_text(json.dumps(metrics, indent=2))\n",
    "print(json.dumps(metrics, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03917c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4725bdce82466f93129fac1c2de41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/194656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c437406f61984543b558bc5b4e7f3e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a22e5129ce440b9bc2186bc45494152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='9126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  19/9126 01:59 < 17:46:45, 0.14 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     64\u001b[39m args = TrainingArguments(\n\u001b[32m     65\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./tmp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m     per_device_train_batch_size=BATCH_SIZE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m     fp16=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     78\u001b[39m )\n\u001b[32m     80\u001b[39m trainer = Trainer(\n\u001b[32m     81\u001b[39m     model=model,\n\u001b[32m     82\u001b[39m     args=args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m     87\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# ---- evaluate & save ----\u001b[39;00m\n\u001b[32m     92\u001b[39m metrics = {\n\u001b[32m     93\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m: trainer.evaluate(ds[\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m     94\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: trainer.evaluate(ds[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     95\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patent-llms/.venv/lib/python3.11/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/patent-llms/.venv/lib/python3.11/site-packages/transformers/trainer.py:2587\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2581\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2582\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2585\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2586\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2587\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2588\u001b[39m ):\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2590\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2591\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Baseline: DistilRoBERTa fine-tune on CPC (Aâ€“H)\n",
    "# ================================================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (DistilBertTokenizerFast, RobertaTokenizerFast,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          Trainer, TrainingArguments)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ---- config ----\n",
    "CSV_DIR = Path(\"../data/cpc_cls\")\n",
    "MODEL_NAME = \"distilroberta-base\"\n",
    "OUT_METRICS = Path(\"../artifacts/baseline_distilroberta.json\")\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "\n",
    "LABELS = list(\"ABCDEFGH\")\n",
    "label2id = {l:i for i,l in enumerate(LABELS)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "\n",
    "# ---- load CSVs into HF datasets ----\n",
    "def load_split(name):\n",
    "    df = pd.read_csv(CSV_DIR / f\"cpc_cls_{name}.csv\")\n",
    "    df[\"labels\"] = df[\"label\"].map(label2id)\n",
    "    return Dataset.from_pandas(df[[\"text\", \"labels\"]], preserve_index=False)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": load_split(\"train\"),\n",
    "    \"validation\": load_split(\"val\"),\n",
    "    \"test\": load_split(\"test\")\n",
    "})\n",
    "\n",
    "# ---- tokenize ----\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "def enc(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, max_length=MAX_LEN)\n",
    "ds = ds.map(enc, batched=True)\n",
    "\n",
    "# ---- model ----\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(LABELS),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# ---- metrics ----\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"weighted_f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "# ---- train ----\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./tmp\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    processing_class=tok,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ---- evaluate & save ----\n",
    "metrics = {\n",
    "    \"val\": trainer.evaluate(ds[\"validation\"]),\n",
    "    \"test\": trainer.evaluate(ds[\"test\"])\n",
    "}\n",
    "\n",
    "OUT_METRICS.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_METRICS.write_text(json.dumps(metrics, indent=2))\n",
    "print(json.dumps(metrics, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
