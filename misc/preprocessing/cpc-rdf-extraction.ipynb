{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e905de",
   "metadata": {},
   "source": [
    "# Extracting all CPC classifications and definitions\n",
    "\n",
    "https://data.epo.org/linked-data/download has the CPC as N-TRIPLES.\n",
    "\n",
    "Extract the specific titles, definitions and tree (broader) from the N-TRIPLES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e5f0d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, os\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "CPC_NS   = \"http://data.epo.org/linked-data/def/cpc/\"\n",
    "SKOS_BR  = \"http://www.w3.org/2004/02/skos/core#broader\"\n",
    "CPC_TTL  = \"http://data.epo.org/linked-data/def/cpc/fullTitle\"\n",
    "\n",
    "SPLIT_RE = re.compile(\n",
    "    r'^<([^>]+)>\\s+<([^>]+)>\\s+(?:(<([^>]+)>)|\"((?:[^\"\\\\]|\\\\.)*)\"(?:\\^\\^<[^>]+>|@[a-zA-Z\\-]+)?)\\s+\\.\\s*$'\n",
    ")\n",
    "REF_RE = re.compile(r\"\\[CPC:\\s*([^\\]]+)\\]\", re.IGNORECASE)\n",
    "\n",
    "def last_seg(uri):\n",
    "    return os.path.basename(urlparse(uri).path)\n",
    "\n",
    "def extract_refs(title):\n",
    "    if not title: return []\n",
    "    refs = []\n",
    "    for block in REF_RE.findall(title):\n",
    "        refs += [x.strip() for x in re.split(r\"[;,]\", block) if x.strip()]\n",
    "    return refs\n",
    "\n",
    "def build_cpc_jsonl(nt_path, out_path):\n",
    "    recs = {}\n",
    "    with open(nt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            m = SPLIT_RE.match(line)\n",
    "            if not m:\n",
    "                continue\n",
    "            s, p, o_uri, o_uri_inner, o_lit = m.groups()\n",
    "            if not s.startswith(CPC_NS):\n",
    "                continue\n",
    "\n",
    "            key = last_seg(s)\n",
    "            r = recs.get(key)\n",
    "            if r is None:\n",
    "                r = recs[key] = {\"key\": key, \"title\": None, \"references\": [], \"broader\": set()}\n",
    "\n",
    "            if p == CPC_TTL and o_lit is not None:\n",
    "                title = o_lit.encode('utf-8').decode('unicode_escape')\n",
    "                r[\"references\"] = extract_refs(title)\n",
    "                \n",
    "                # Remove [CPC: ...]\n",
    "                title = re.sub(r\"\\[CPC:[^\\]]+\\]\", \"\", title)\n",
    "\n",
    "                # Remove any parentheses containing 'take precedence' or 'takes precedence'\n",
    "                title = re.sub(r\"\\([^)]*take(?:s)? precedence[^)]*\\)\", \"\", title, flags=re.IGNORECASE)\n",
    "\n",
    "                # Remove () or {} with no letters inside\n",
    "                title = re.sub(r\"\\(\\s*[^a-zA-Z]*\\)\", \"\", title)\n",
    "                title = re.sub(r\"\\{\\s*[^a-zA-Z]*\\}\", \"\", title)\n",
    "\n",
    "                # Collapse multiple spaces and commas\n",
    "                title = re.sub(r\"\\s{2,}\", \" \", title)         # multiple spaces → single\n",
    "                title = re.sub(r\",\\s*,+\", \",\", title)         # \", , ,\" → \",\"\n",
    "                title = re.sub(r\"\\s+,\", \",\", title)           # \" ,word\" → \",word\"\n",
    "                title = re.sub(r\",\\s+\", \", \", title)          # \",word\" → \", word\"\n",
    "                r[\"title\"] = title\n",
    "\n",
    "            elif p == SKOS_BR and o_uri_inner and o_uri_inner.startswith(CPC_NS):\n",
    "                r[\"broader\"].add(last_seg(o_uri_inner))\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
    "        for r in recs.values():\n",
    "            r[\"broader\"] = sorted(r[\"broader\"])\n",
    "            out.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# --- use it ---\n",
    "nt_file = \"../data/cpc.nt\"\n",
    "out_file = \"../data/cpc.jsonl\"\n",
    "build_cpc_jsonl(nt_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a531f",
   "metadata": {},
   "source": [
    "## Quick analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8a51be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 261962\n",
      "Duplicate keys: 0\n",
      "Missing titles: 11\n",
      "[(20383, 'H0'), (38239, 'G9'), (44731, 'G1'), (63581, 'F9'), (88586, 'E9'), (113544, 'D9'), (116385, 'Y0'), (138441, 'C9'), (163627, 'B9'), (189069, 'A9'), (258333, 'scheme')] ...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "jsonl_file = \"../data/cpc.jsonl\"\n",
    "\n",
    "keys_seen = set()\n",
    "duplicates = []\n",
    "missing_title = []\n",
    "\n",
    "with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        rec = json.loads(line)\n",
    "        key = rec.get(\"key\")\n",
    "        title = rec.get(\"title\")\n",
    "\n",
    "        if key in keys_seen:\n",
    "            duplicates.append((i, key))\n",
    "        else:\n",
    "            keys_seen.add(key)\n",
    "\n",
    "        if not title or not title.strip():\n",
    "            missing_title.append((i, key))\n",
    "\n",
    "print(f\"Total records: {len(keys_seen)}\")\n",
    "print(f\"Duplicate keys: {len(duplicates)}\")\n",
    "if duplicates:\n",
    "    print(duplicates[:10], \"...\")\n",
    "\n",
    "print(f\"Missing titles: {len(missing_title)}\")\n",
    "if missing_title:\n",
    "    print(missing_title, \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49961cc8",
   "metadata": {},
   "source": [
    "## Adding a fullTitle key by walking up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35ed53c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote → ../data/cpc_full.jsonl (261962 records)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from functools import lru_cache\n",
    "\n",
    "in_file  = \"../data/cpc.jsonl\"\n",
    "out_file = \"../data/cpc_full.jsonl\"\n",
    "\n",
    "# Load nodes\n",
    "nodes = {}\n",
    "with open(in_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rec = json.loads(line)\n",
    "        nodes[rec[\"key\"]] = {\n",
    "            \"title\":   rec.get(\"title\") or rec[\"key\"],\n",
    "            \"broader\": rec.get(\"broader\") or [],\n",
    "            \"refs\":    rec.get(\"references\", []),\n",
    "        }\n",
    "\n",
    "parents = {k: v[\"broader\"] for k, v in nodes.items()}\n",
    "def title_of(k): return nodes.get(k, {}).get(\"title\") or k\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def paths_to_roots(key):\n",
    "    def dfs(k, seen):\n",
    "        if k in seen: return [[k]]  # break cycles\n",
    "        seen = seen | {k}\n",
    "        ps = parents.get(k, [])\n",
    "        if not ps: return [[k]]\n",
    "        out = []\n",
    "        for p in ps:\n",
    "            if p not in nodes:\n",
    "                out.append([p, k])\n",
    "            else:\n",
    "                for up in dfs(p, seen):\n",
    "                    out.append(up + [k])\n",
    "        return out\n",
    "    return tuple(tuple(p) for p in dfs(key, frozenset()))\n",
    "\n",
    "def pick_single_path(path_keys):\n",
    "    # Expect exactly one; if multiple ever appear, pick the longest and note it.\n",
    "    if not path_keys: return ()\n",
    "    if len(path_keys) == 1: return path_keys[0]\n",
    "    # fallback: choose the longest path\n",
    "    return max(path_keys, key=len)\n",
    "\n",
    "# Write simplified JSONL\n",
    "with open(out_file, \"w\", encoding=\"utf-8\") as out:\n",
    "    for key in nodes.keys():\n",
    "        path_keys  = paths_to_roots(key)\n",
    "        path       = pick_single_path(path_keys)\n",
    "        full_title = \" → \".join(title_of(k) for k in path)\n",
    "        tree_path  = [{\"key\": k, \"title\": title_of(k)} for k in path]\n",
    "\n",
    "        rec = {\n",
    "            \"key\": key,\n",
    "            \"title\": title_of(key),\n",
    "            \"references\": nodes[key][\"refs\"],\n",
    "            \"broader\": parents.get(key, []),\n",
    "            \"fullTitle\": full_title,   # single string\n",
    "            \"treePath\": tree_path      # single path (root → leaf)\n",
    "        }\n",
    "        out.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote → {out_file} ({len(nodes)} records)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671aabb",
   "metadata": {},
   "source": [
    "### View random record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "740941e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"key\": \"C25D7-065\",\n",
      "  \"title\": \"{Diaphragms}\",\n",
      "  \"references\": [],\n",
      "  \"broader\": [\n",
      "    \"C25D7-0614\"\n",
      "  ],\n",
      "  \"fullTitle\": \"CHEMISTRY; METALLURGY → METALLURGY → ELECTROLYTIC OR ELECTROPHORETIC PROCESSES; APPARATUS THEREFOR → PROCESSES FOR THE ELECTROLYTIC OR ELECTROPHORETIC PRODUCTION OF COATINGS; ELECTROFORMING; APPARATUS THEREFOR → Electroplating characterised by the article coated → Wires; Strips; Foils → {Strips or foils} → {Diaphragms}\",\n",
      "  \"treePath\": [\n",
      "    {\n",
      "      \"key\": \"C\",\n",
      "      \"title\": \"CHEMISTRY; METALLURGY\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C2\",\n",
      "      \"title\": \"METALLURGY\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25\",\n",
      "      \"title\": \"ELECTROLYTIC OR ELECTROPHORETIC PROCESSES; APPARATUS THEREFOR\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25D\",\n",
      "      \"title\": \"PROCESSES FOR THE ELECTROLYTIC OR ELECTROPHORETIC PRODUCTION OF COATINGS; ELECTROFORMING; APPARATUS THEREFOR\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25D7-00\",\n",
      "      \"title\": \"Electroplating characterised by the article coated\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25D7-06\",\n",
      "      \"title\": \"Wires; Strips; Foils\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25D7-0614\",\n",
      "      \"title\": \"{Strips or foils}\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"C25D7-065\",\n",
      "      \"title\": \"{Diaphragms}\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, random\n",
    "\n",
    "def random_record(jsonl_path, n=1):\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    for rec in random.sample(lines, n):\n",
    "        obj = json.loads(rec)\n",
    "        print(json.dumps(obj, ensure_ascii=False, indent=2))\n",
    "\n",
    "# Example:\n",
    "random_record(\"../data/cpc_full.jsonl\", n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd00d89",
   "metadata": {},
   "source": [
    "# Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f79c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"key\": \"Y02E\",\n",
      "  \"title\": \"REDUCTION OF GREENHOUSE GAS [GHG] EMISSIONS, RELATED TO ENERGY GENERATION, TRANSMISSION OR DISTRIBUTION\",\n",
      "  \"references\": [],\n",
      "  \"broader\": [\n",
      "    \"Y02\"\n",
      "  ],\n",
      "  \"fullTitle\": \"GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS → Y0 → TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE → REDUCTION OF GREENHOUSE GAS [GHG] EMISSIONS, RELATED TO ENERGY GENERATION, TRANSMISSION OR DISTRIBUTION\",\n",
      "  \"treePath\": [\n",
      "    {\n",
      "      \"key\": \"Y\",\n",
      "      \"title\": \"GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Y0\",\n",
      "      \"title\": \"Y0\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Y02\",\n",
      "      \"title\": \"TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"Y02E\",\n",
      "      \"title\": \"REDUCTION OF GREENHOUSE GAS [GHG] EMISSIONS, RELATED TO ENERGY GENERATION, TRANSMISSION OR DISTRIBUTION\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_record_by_key(jsonl_path, key):\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            rec = json.loads(line)\n",
    "            if rec.get(\"key\") == key:\n",
    "                return rec\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "record = get_record_by_key(\"../data/cpc_full.jsonl\", \"Y02E\")\n",
    "if record:\n",
    "    print(json.dumps(record, ensure_ascii=False, indent=2))\n",
    "else:\n",
    "    print(\"Key not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89748828",
   "metadata": {},
   "source": [
    "## Upload to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6541148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "path = \"../data/cpc_full.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0c97ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dcbadfb1a14fe6afe59e0450e15d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"json\", data_files=path, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c63f486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/datasets/mhurhangee/cpc-classifications', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mhurhangee/cpc-classifications')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "repo_id = \"mhurhangee/cpc-classifications\"   # pick a name\n",
    "create_repo(repo_id, repo_type=\"dataset\", private=False, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c54d16c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e01dd46baf49ed861aed28fbfbae16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e5051121db42c9a98b17a4f5d8c5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/262 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mhurhangee/cpc-classifications/commit/c1df8e3bac8a5b8c6363763c29d2ab3bd3d95a1f', commit_message='Upload dataset', commit_description='', oid='c1df8e3bac8a5b8c6363763c29d2ab3bd3d95a1f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mhurhangee/cpc-classifications', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mhurhangee/cpc-classifications'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "readme = \"\"\"\\\n",
    "# CPC Classifications (Full Titles)\n",
    "\n",
    "Extracted from the [EPO's CPC RDF](https://data.epo.org/linked-data/download) data from 07 Aug 2025.\n",
    "\n",
    "Titles were cleaned to remove references and the references extracted.\n",
    "\n",
    "Fields:\n",
    "- `key`: CPC symbol (e.g., B29C45-00)\n",
    "- `title`: cleaned CPC title\n",
    "- `references`: list extracted from `[CPC: ...]`\n",
    "- `broader`: parent keys\n",
    "- `fullTitle`: concatenated hierarchy title (root → leaf)\n",
    "- `treePath`: list of {key, title} from root → leaf\n",
    "\"\"\"\n",
    "api.upload_file(\n",
    "    path_or_fileobj=readme.encode(),\n",
    "    path_in_repo=\"README.md\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf04166",
   "metadata": {},
   "source": [
    "### Misc\n",
    "\n",
    "#### Check number of titles and tree paths\n",
    "\n",
    "Originally, I wasn't sure if all trees only had one broader node, so one fullTitle and one treePath. This was to check when I saved the fullTitles and treePaths as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bc7930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 261962 records\n",
      "fullTitles with >1 entry: 0\n",
      "treePaths with >1 entry: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def check_single_path(jsonl_path):\n",
    "    multi_full = []\n",
    "    multi_tree = []\n",
    "    total = 0\n",
    "\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            rec = json.loads(line)\n",
    "            total += 1\n",
    "            if len(rec.get(\"fullTitles\", [])) > 1:\n",
    "                multi_full.append(rec[\"key\"])\n",
    "            if len(rec.get(\"treePaths\", [])) > 1:\n",
    "                multi_tree.append(rec[\"key\"])\n",
    "\n",
    "    print(f\"Checked {total} records\")\n",
    "    print(f\"fullTitles with >1 entry: {len(multi_full)}\")\n",
    "    print(f\"treePaths with >1 entry: {len(multi_tree)}\")\n",
    "\n",
    "    if multi_full:\n",
    "        print(\"Example keys with multiple fullTitles:\", multi_full[:10])\n",
    "    if multi_tree:\n",
    "        print(\"Example keys with multiple treePaths:\", multi_tree[:10])\n",
    "\n",
    "# Example usage\n",
    "check_single_path(\"../data/cpc_full.jsonl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
